{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from catboost import CatBoostClassifier\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quests_0_4 = [1, 3] \n",
    "quests_5_12 = [4, 5, 6, 7, 8, 9, 10, 11] \n",
    "quests_13_22 = [14, 15, 16, 17] \n",
    "\n",
    "list_kol_f = {\n",
    "    1:140,3:110,\n",
    "    4:110, 5:220, 6:120, 7:110, 8:110, 9:100, 10:120, 11:120,\n",
    "    14: 110, 15:160, 16:105, 17:140             \n",
    "             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {}\n",
    "best_threshold = 0.63"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Reading\n",
    "dir = '/kaggle/input/catbust/'\n",
    "for q in quests_0_4 + quests_5_12 + quests_13_22:\n",
    "    models[q] = CatBoostClassifier().load_model(dir+f'cat_model_{q}.bin')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Infer Test Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jo_wilder\n",
    "\n",
    "try:\n",
    "    jo_wilder.make_env.__called__ = False\n",
    "    env.__called__ = False\n",
    "    type(env)._state = type(type(env)._state).__dict__['INIT']\n",
    "except:\n",
    "    pass\n",
    "\n",
    "env = jo_wilder.make_env()\n",
    "iter_test = env.iter_test()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_df = pd.read_csv('feature_sort.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delt_time_def(df):\n",
    "    df.sort_values(by=['session_id', 'elapsed_time'], inplace=True)\n",
    "    df['d_time'] = df['elapsed_time'].diff(1)\n",
    "    df['d_time'].fillna(0, inplace=True)\n",
    "    df['delt_time'] = df['d_time'].clip(0, 103000)\n",
    "    df['delt_time_next'] = df['delt_time'].shift(-1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_engineer(train, kol_f):\n",
    "    global kol_col, kol_col_max\n",
    "    kol_col = 9\n",
    "    kol_col_max = 11+kol_f*2\n",
    "    col = [i for i in range(0,kol_col_max)]\n",
    "    new_train = pd.DataFrame(index=train['session_id'].unique(), columns=col, dtype=np.float16)  \n",
    "    new_train[10] = new_train.index # \"session_id\"    \n",
    "\n",
    "    new_train[0] = train.groupby(['session_id'])['d_time'].quantile(q=0.3)\n",
    "    new_train[1] = train.groupby(['session_id'])['d_time'].quantile(q=0.8)\n",
    "    new_train[2] = train.groupby(['session_id'])['d_time'].quantile(q=0.5)\n",
    "    new_train[3] = train.groupby(['session_id'])['d_time'].quantile(q=0.65)\n",
    "    new_train[4] = train.groupby(['session_id'])['hover_duration'].agg('mean')\n",
    "    new_train[5] = train.groupby(['session_id'])['hover_duration'].agg('std')    \n",
    "    new_train[6] = new_train[10].apply(lambda x: int(str(x)[:2])).astype(np.uint8) # \"year\"\n",
    "    new_train[7] = new_train[10].apply(lambda x: int(str(x)[2:4])+1).astype(np.uint8) # \"month\"\n",
    "    new_train[8] = new_train[10].apply(lambda x: int(str(x)[4:6])).astype(np.uint8) # \"day\"\n",
    "    new_train[9] = new_train[10].apply(lambda x: int(str(x)[6:8])).astype(np.uint8) + new_train[10].apply(lambda x: int(str(x)[8:10])).astype(np.uint8)/60\n",
    "    new_train[10] = 0\n",
    "    new_train = new_train.fillna(-1)\n",
    "    \n",
    "    return new_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_next_t_otvet(row_f, new_train, train, gran_1, gran_2, i):\n",
    "    global kol_col\n",
    "    kol_col +=1\n",
    "    col1 = row_f['col1']\n",
    "    val1 = row_f['val1']\n",
    "    maska = (train[col1] == val1)\n",
    "    if row_f['kol_col'] == 1:      \n",
    "        new_train[kol_col] = train[maska]['delt_time_next'].sum()\n",
    "        if gran_1:\n",
    "            kol_col +=1\n",
    "            new_train[kol_col] = train[maska]['delt_time'].mean()\n",
    "        if gran_2:\n",
    "            kol_col +=1\n",
    "            new_train[kol_col] = train[maska]['index'].count()          \n",
    "    elif row_f['kol_col'] == 2: \n",
    "        col2 = row_f['col2']\n",
    "        val2 = row_f['val2']\n",
    "        maska = maska & (train[col2] == val2)        \n",
    "        new_train[kol_col] = train[maska]['delt_time_next'].sum()\n",
    "        if gran_1:\n",
    "            kol_col +=1\n",
    "            new_train[kol_col] = train[maska]['delt_time'].mean()\n",
    "        if gran_2:\n",
    "            kol_col +=1\n",
    "            new_train[kol_col] = train[maska]['index'].count()\n",
    "    return new_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_quest_otvet(new_train, train, quest, kol_f):\n",
    "    global kol_col\n",
    "    kol_col = 9\n",
    "    g1 = 0.7 \n",
    "    g2 = 0.3 \n",
    "\n",
    "    feature_q = feature_df[feature_df['quest'] == quest].copy()\n",
    "    feature_q.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    gran1 = round(kol_f * g1)\n",
    "    gran2 = round(kol_f * g2)    \n",
    "    for i in range(0, kol_f):         \n",
    "        row_f = feature_q.loc[i]\n",
    "        new_train = feature_next_t_otvet(row_f, new_train, train, i < gran1, i <  gran2, i) \n",
    "    col = [i for i in range(0,kol_col+1)]\n",
    "    return new_train[col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_end4 = 0\n",
    "g_end5 = 0\n",
    "\n",
    "list_q = {'0-4':quests_0_4, '5-12':quests_5_12, '13-22':quests_13_22}\n",
    "for (test, sam_sub) in iter_test:\n",
    "    sam_sub['question'] = [int(label.split('_')[1][1:]) for label in sam_sub['session_id']]    \n",
    "    grp = test.level_group.values[0]   \n",
    "    sam_sub['correct'] = 1\n",
    "    sam_sub.loc[sam_sub.question.isin([5, 8, 10, 13, 15]), 'correct'] = 0  \n",
    "    old_train = delt_time_def(test[test.level_group == grp])\n",
    "       \n",
    "    for q in list_q[grp]:\n",
    "        \n",
    "        start4 = time.time()\n",
    "        new_train = feature_engineer(old_train, list_kol_f[q])\n",
    "        new_train = feature_quest_otvet(new_train, old_train, q, list_kol_f[q])\n",
    "#         new_train = feature_quest(new_train, old_train, q, kol_f)\n",
    "        \n",
    "        end4 = time.time() - start4\n",
    "        g_end4 += end4\n",
    "        \n",
    "        start5 = time.time()        \n",
    "        \n",
    "        clf = models[f'{q}']\n",
    "        p = clf.predict_proba(new_train.astype('float32'))[:,1]        \n",
    "        \n",
    "        end5 = time.time() - start5\n",
    "        g_end5 += end5\n",
    "             \n",
    "        \n",
    "        mask = sam_sub.question == q \n",
    "        x = int(p[0]>best_threshold)\n",
    "        sam_sub.loc[mask,'correct'] = x      \n",
    "        \n",
    "        \n",
    "    sam_sub = sam_sub[['session_id', 'correct']]      \n",
    "    env.predict(sam_sub)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA submission.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('submission.csv')\n",
    "print( df.shape )\n",
    "df.head(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
